---
- hosts: hadoopnodes
  become: yes
  tasks:
    - name: install python packages.
      apt:
        name: "{{ item }}"
        state: present
      with_items:
        - python-networkx
        - python-pandas

- name: Deploy the dataset
  tags: data
  hosts: frontendnodes

  vars:
    download_dir: "/tmp"
    datafile: "simu-0-99.zip"

    db_dir: "/tmp/network"
    db4_path: "{{ db_dir }}/{{ datafile | splitext | first }}"
    databases:
      4:
        url: "http://149.165.159.58/data/FG491/ma47/simu-0-99.zip"

  tasks:

    - name: install unzip
      become: yes
      apt:
        name: unzip
        state: present

    - name: prepare the directories for dataset and output files
      file:
        path: "{{ item }}"
        state: directory
      with_items:
        - "{{ download_dir }}"
        - "{{ db_dir }}"
        - "/tmp/graphs"


    - name: extract files
      become: yes
      unarchive:
        src: "{{ datafile }}"
        dest: "{{ db_dir }}"
        owner: hadoop
        group: hadoop
        creates: "{{ db4_path }}"

    - name: fix permissions
      become: yes
      file:
        path: "{{ db_dir }}"
        owner: hadoop
        group: hadoop
        recurse: yes

    - name: import 100 csv files into hdfs
      become: yes
      become_user: hadoop
      shell: "sh -lc 'hadoop fs -put {{ db_dir }} /network'"

    - name: download the code script graph_generator.py
      copy:
        src: "graph_generator.py"
        dest: "{{ download_dir }}"
